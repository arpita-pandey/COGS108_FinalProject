{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Arpita Pandey \n",
    "- Karina Shah \n",
    "- Sahithi Josyam\n",
    "- Kanishk Hari\n",
    "- Mihir Joshi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is the relationship between unemployment rates of specific job titles and the adaptation of AI across industries in the U.S. from 2010 to 2023?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rise of generative AI tools like ChatGPT, Gemini, and Github Copilot have caught global attention through their advancements in machine learning. With it's rapid growth, their have been talks on how to utilize AI in various industries. Thus, through our research, we hope to dvelve into how artificial intelligence is affecting employment rates in these various industries in the past few years. \n",
    "\n",
    "\n",
    "Generative AI has shown potential for immense economic growth. In a report done by Mkinsey & Company, it was discovered that Generative AI could add an estimated 2.6 trillion to 4.6 trillion dollars to the global economy.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) But, this growth isn't uniform across industries. Looking into various industries, research shows that AI could fall short in 4 major areas: customer operations, marketing and sales, software engineering, and R&D.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Thus, it is important to further examine the affects of AI, in various industries, as well as the job opportunities that come with. \n",
    "\n",
    "With the innovations of Gen AI there are growing concerns on its affects on job displacement. Due to AI's ability to automate certain tasks and daily cognitive processes, there is concerns on it taking over various vocations. A recent study by Goldman Sachs states that Generative AI could automate up to 300 million jobs in the US and Europe. <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) Through these studies, we see that many jobs have a potential of being taken up by Generative AI, but we hope to further dvelve into what industries and job titles seem most at risk of job displacement, and which industries still have potential for job growth.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Chui, Michael, et al. The Economic Potential of Generative AI, June 2023, [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier#introduction]\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Rege, Manjeet, and Hemachandran K. “Tommie Experts: Generative AI’s Real-World Impact on Job Markets - Newsroom: University of St. Thomas.” Newsroom | University of St. Thomas, 4 Nov. 2024, [https://news.stthomas.edu/generative-ais-real-world-impact-on-job-markets/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict that higher AI adoption rates in various industry sectors will be associated with an increase in job displacement, leading to short-term rises in unemployment rates. However, we also anticipate that over time, AI-related job creation, retraining programs, and shifts in workforce demand will mitigate these effects, potentially stabilizing or even reducing unemployment in industries that successfully adapt.\n",
    "\n",
    "This hypothesis is based on the expectation that AI will initially disrupt traditional job roles, particularly in sectors with high automation potential, but will also drive new opportunities in AI-related fields. Industries that invest in retraining and upskilling programs may experience lower long-term unemployment, while those slower to adapt may face prolonged job losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explain what the **ideal** dataset you would want to answer this question. (This should include: What variables? How many observations? Who/what/how would these data be collected? How would these data be stored/organized?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ideal dataset to explore the relationship between the unemployment rate and AI’s impact on jobs would require two separate groups of data. First, we’d need unemployment data over time, grouped by industry and job categories. Second, we’d need detailed data on AI adoption rates and the industry sectors where AI is being implemented.\n",
    "\n",
    "For this project, we’ll define AI adoption as the rate at which industries and companies integrate AI systems into their workflows. AI adaptation, on the other hand, refers to how industries and workers adjust to AI integration — whether through task automation, retraining programs, or evolving job roles. We are going to be focused on the former, where we want to determine how the industry is adopting AI and how that is either leading to falling or rising unemployment rates.\n",
    "\n",
    "We would be using the measurements of AI impact and adaptation based on the aggregate descriptions of the sources that the data would be collected from as we lack the resources to conduct a large enough sample to gain accurate insights.\n",
    "\n",
    "The ideal dataset would include variables such as:\n",
    "\n",
    "Unemployment rate: Percentage of unemployed workers by industry and job category over time.\n",
    "\n",
    "AI adoption rates: Percentage of companies within an industry that have integrated AI technologies.\n",
    "\n",
    "Job titles: Names of various job roles across different industries.\n",
    "\n",
    "AI impact: Percentage representation of AI’s influence on the respective job title (e.g., task automation rate).\n",
    "\n",
    "Tasks: Numerical count of human-performed tasks associated with each job title.\n",
    "\n",
    "AI models: Count of AI models or systems implemented for the respective job role.\n",
    "\n",
    "AI_Workload_Ratio: A computed ratio representing the workload distribution between human tasks and AI models.\n",
    "\n",
    "Industry sectors: Broader categories of the economy, like finance, healthcare, and manufacturing.\n",
    "\n",
    "Company sizes: Classification of companies as small, medium, or large.\n",
    "\n",
    "Geographic locations: Data segmented by state, city, or region.\n",
    "\n",
    "AI investment: Capital expenditure on AI technologies by companies and industries.\n",
    "\n",
    "AI-related job creation: Number of new roles emerging from AI implementation.\n",
    "\n",
    "Skills gaps: Identified gaps between current workforce skills and the skills required for AI-integrated roles.\n",
    "\n",
    "Retraining programs: Availability and participation rates in workforce upskilling initiatives.\n",
    "\n",
    "The dataset should ideally contain thousands of data points, covering all 50 states, at least 10 industry sectors, and 100 companies of varying sizes. Data should be collected over a 10-year period and updated as often as possible, ideally monthly. Data sources would include government agencies, industry surveys, AI companies, and job market platforms.\n",
    "\n",
    "Given the large volume of data, we would store it in CSV files and load it as Pandas dataframes in Python. Dataframes would allow us to merge, clean, and isolate data as needed for our analyses. Python also offers fast and robust ways to visualize and model the data. For any analysis requiring larger compute power, we’d have access to a data hub to manage and process the datasets efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Search for potential **real** datasets that could provide you with something useful for this project.  You do not have to find every piece of data you will use, but you do need to have demonstrated some idea that (a) this data is gettable and (b) that this data may be different from what your ideal is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found some potential example data sets that we could use for this project. \n",
    "\n",
    "The first one is called \"From Data Entry to CEO: The AI Job Threat Index.\" This data set contains information about the number of AI models available, the impact, workload ratio, and the industry that each data point is from. This meets many of the criteria that we wanted in our ideal data set. (https://www.kaggle.com/datasets/manavgupta92/from-data-entry-to-ceo-the-ai-job-threat-index)\n",
    "\n",
    "\n",
    "The second one is called \"US Monthly Unemployment Rate 1948 - Present\" which contains monthly unemployment related data for the last 70 years. This data is almost ideal but it does not include industry or company data which may be helpful for our analysis. (https://www.kaggle.com/datasets/tunguz/us-monthly-unemployment-rate-1948-present)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within our two datasets, our first dataset \"From Data Entry to CEO: The AI Job Threat Index\" has no personal data included, so there is no concern for privacy regarding this dataset. Within our second dataset, \"US Monthly Unemployment Rate 1948 - Present\", there is also no personal data included, as this is just a survey of unemployment rates per month, so there is no privacy concerns as well. However, bias concerns exist within the first dataset. We discovered that the owner of the dataset scrapped the data from multiple \"reputable\" sources, however, these sources utilized to scrape the data were not mentioned. As such, it is difficult to pinpoint where exactly the data came from for all of the data, and this is something we will have to closely monitor and address if we find the original source. \n",
    "Moreover, our second dataset has data until 2019, so we would need to find another source that gives us the unemployment rate per month from 2020 to present. Since the data we deal with is mostly regarding the efficiency of AI in jobs and how well it has done a certain job, numeric data will be the primary focus of this project, and as such, forging of numeric data is very common in order to make sure that a certain bias exists within job displacement due to artificial intelligence. To handle these issues, we will cross-reference the data in the dataset with information online (ideally, we would try to find the original data, but we will gather information from multiple sources to verify this information). Other than this, there are no other issues related to topic area, data, and analyses regarding data privacy and equitable impact, as the data merely shows how impacted certain roles were in correspondance to unemployment rates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After reading COGS 108 Team Policies, we have set the following as our team's expectations: \n",
    "\n",
    "* Communication: Communication among team members will take place virtually on Discord and in-person as needed. We will meet weekly or as-needed on Thursdays at 6:30. To ensure that all view points are heard and valued, our team will be \"blunt but polite\". Additionally, decisions will be made by majority-vote.\n",
    "* Responsibility: All work will be split up equally. This being said, the work assigned to an individual also allows for collaboration among others to ensure that every individual is able to contribute (e.g. not one person will do all the coding work). If a team member needs assistance with a task, then there will be no hesitancy in providing help. Tasks will be divided by comfortability of an individual handling it but can be rotated weekly such that each team member can try something new.  \n",
    "* Team members will be aligned as closely as possible with the plan. If anybody forsees an issue arising, then they will notify the others as soon as possible so everybody ensures proper preparation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team's anticipated timeline for the project: \n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/28  |  5 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis for the final topic and begin the initial background research | \n",
    "| 2/4  |  5 PM |  Do background research on topic | Discuss ideal dataset(s) fitting for our topic; start the initial project proposal draft| \n",
    "| 2/9| 5 PM | Refine the project proposal finally; Search for datasets  | Submit the proposal; Begin discussing wrangling and possible approaches for data analysis;Assign group members different parts   |\n",
    "| 2/13  | 6:30 PM  | Import & Wrangle Data (Mihir Joshi); EDA (Sahithi Josyam) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 2 PM  | Finalize wrangling/EDA; Begin Analysis (Arpita Pandey; Karina Shah) | Refine the current analysis for topic and complete project check-in! |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Kanishk Hari)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
